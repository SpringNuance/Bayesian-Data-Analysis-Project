theme(legend.position = "bottom") +
theme(plot.title = element_text(hjust = 0.5)) +
ggtitle(paste("WHOIS in",numberOfBenignURLs,"benign URLs\n(complete/incomplete for WHOIS)")) +
guides(fill=guide_legend(title=""))
grid.arrange(p1, p2, ncol = 2)
options(dplyr.summarise.inform = FALSE)
# Group the dataframe by geo_loc and count the number of rows for each country
train_websites_count <- train_websites %>%
group_by(geo_loc) %>%
summarize(count = n() ) %>%
top_n(10, count)
# Count the number of benign and malicious URLs for each country
train_websites_count_label <- train_websites %>%
filter(geo_loc %in% train_websites_count$geo_loc) %>%
group_by(geo_loc, label) %>%
summarize(count = n())
# Plot the bar chart
ggplot(train_websites_count_label, aes(x = geo_loc, y = count, fill = label)) +
geom_bar(stat = "identity", position = "stack") +
scale_fill_manual(values = c("red", "blue"),
labels = c("malicious","benign")) +
xlab("Country") +
ylab("Number of URLs") +
ggtitle("Distribution of benign and malicious URLs of top 10 recorded countries") +
guides(fill = guide_legend(title = "Label")) +
theme(axis.text.x = element_text(angle = 30, hjust = 0.5, vjust = 0.5, size = 10,
margin = margin(r = -20, unit = "pt"),
family = "serif",
lineheight = 0.9, color = "black"))
print(train_websites_count)
print(train_websites_count_label)
train_websites_top_10 <- train_websites %>%
filter(geo_loc %in% train_websites_count$geo_loc)
test_websites_top_10 <- test_websites %>%
filter(geo_loc %in% train_websites_count$geo_loc)
print(nrow(train_websites_top_10))
print(nrow(test_websites_top_10))
keptColNames = c("label", "geo_loc", "js_len", "js_obf_len", "https", "who_is")
train_websites_top_10 <- train_websites_top_10[, keptColNames]
test_websites_top_10 <- test_websites_top_10[, keptColNames]
print(train_websites_top_10)
print(test_websites_top_10)
keptColNames = c("label", "geo_loc", "js_len", "js_obf_len", "https", "who_is")
train_websites_top_10 <- train_websites_top_10[, keptColNames]
test_websites_top_10 <- test_websites_top_10[, keptColNames]
print(train_websites_top_10)
print(test_websites_top_10)
keptColNames = c("label", "geo_loc", "js_len", "js_obf_len", "https", "who_is")
train_websites$safety <- ifelse(train_websites$https == "yes" &
train_websites$who_is == "complete", 1,
ifelse(train_websites$https == "no"
& train_websites$who_is == "complete", 2,
ifelse(train_websites$https == "yes" &
train_websites$who_is == "incomplete", 3, 4)))
train_websites_top_10 <- train_websites_top_10[, keptColNames]
test_websites_top_10 <- test_websites_top_10[, keptColNames]
print(train_websites_top_10)
print(test_websites_top_10)
train_websites$safety <- ifelse(train_websites$https == "yes" &
train_websites$who_is == "complete", 1,
ifelse(train_websites$https == "no"
& train_websites$who_is == "complete", 2,
ifelse(train_websites$https == "yes" &
train_websites$who_is == "incomplete", 3, 4)))
keptColNames = c("label", "geo_loc", "js_len", "js_obf_len", "safety")
train_websites_top_10 <- train_websites_top_10[, keptColNames]
train_websites_top_10$safety <- ifelse(train_websites$https == "yes" &
train_websites$who_is == "complete", 1,
ifelse(train_websites$https == "no"
& train_websites$who_is == "complete", 2,
ifelse(train_websites$https == "yes" &
train_websites$who_is == "incomplete", 3, 4)))
train_websites_top_10$safety <- ifelse(train_websites_top_10$https == "yes" &
train_websites_top_10$who_is == "complete", 1,
ifelse(train_websites_top_10$https == "no"
& train_websites_top_10$who_is == "complete", 2,
ifelse(train_websites_top_10$https == "yes" &
train_websites_top_10$who_is == "incomplete", 3, 4)))
keptColNames = c("label", "geo_loc", "js_len", "js_obf_len", "safety")
train_websites_top_10 <- train_websites_top_10[, keptColNames]
test_websites_top_10 <- test_websites_top_10[, keptColNames]
train_websites_top_10$safety <- ifelse(train_websites_top_10$https == "yes" &
train_websites_top_10$who_is == "complete", 1,
ifelse(train_websites_top_10$https == "no"
& train_websites_top_10$who_is == "complete", 2,
ifelse(train_websites_top_10$https == "yes" &
train_websites_top_10$who_is == "incomplete", 3, 4)))
train_websites_top_10 <- train_websites %>%
filter(geo_loc %in% train_websites_count$geo_loc)
test_websites_top_10 <- test_websites %>%
filter(geo_loc %in% train_websites_count$geo_loc)
print(nrow(train_websites_top_10))
print(nrow(test_websites_top_10))
train_websites_top_10$safety <- ifelse(train_websites_top_10$https == "yes" &
train_websites_top_10$who_is == "complete", 1,
ifelse(train_websites_top_10$https == "no"
& train_websites_top_10$who_is == "complete", 2,
ifelse(train_websites_top_10$https == "yes" &
train_websites_top_10$who_is == "incomplete", 3, 4)))
test_websites_top_10$safety <- ifelse(test_websites_top_10$https == "yes" &
test_websites_top_10$who_is == "complete", 1,
ifelse(test_websites_top_10$https == "no"
& test_websites_top_10$who_is == "complete", 2,
ifelse(test_websites_top_10$https == "yes" &
test_websites_top_10$who_is == "incomplete", 3, 4)))
keptColNames = c("label", "geo_loc", "js_len", "js_obf_len", "safety")
train_websites_top_10 <- train_websites_top_10[, keptColNames]
test_websites_top_10 <- test_websites_top_10[, keptColNames]
print(train_websites_top_10)
print(test_websites_top_10)
train_websites_top_10_bad <- train_websites_top_10 %>%
filter(label =="bad")
train_websites_top_10_good <- train_websites_top_10 %>%
filter(label =="bad")
print(nrow(train_websites_top_10_bad))
print(nrow(train_websites_top_10_good))
train_websites_top_10_bad <- train_websites_top_10 %>%
filter(label =="bad")
train_websites_top_10_good <- train_websites_top_10 %>%
filter(label =="good")
print(nrow(train_websites_top_10_bad))
print(nrow(train_websites_top_10_good))
# Count the number of rows for each combination of https and who_is
train_websites_count <- train_websites %>%
filter(label == "bad")
numberOfMaliciousURLs <- nrow(train_websites_count)
train_websites_count <- train_websites %>%
filter(label == "bad") %>%
group_by(https) %>%
summarize(count = n())
print(train_websites_count)
print(interaction(train_websites_count$who_is))
# Create a pie chart with a legend
p1 <- ggplot(train_websites_count, aes(x = "", y = count, fill = interaction(https))) +
geom_bar(width = 1, stat = "identity") +
coord_polar("y", start = 0, direction = 1) +
scale_fill_manual(values = c("red", "green"), labels=c("no","yes")) +
theme(legend.position = "bottom") +
theme(plot.title = element_text(hjust = 0.5)) +
ggtitle(paste("HTTPS in",numberOfMaliciousURLs,"malicious URLs\n(yes/no for HTTPS)")) +
guides(fill=guide_legend(title=""))
# Count the number of rows for each combination of https and who_is
train_websites_count <- train_websites %>%
filter(label == "bad")
numberOfMaliciousURLs <- nrow(train_websites_count)
train_websites_count <- train_websites %>%
filter(label == "bad") %>%
group_by(who_is) %>%
summarize(count = n()) %>%
arrange(desc(count))
print(train_websites_count)
print(interaction(train_websites_count$who_is))
# Create a pie chart with a legend
p2 <- ggplot(train_websites_count, aes(x = "", y = count, fill = interaction(who_is))) +
geom_bar(width = 1, stat = "identity") +
coord_polar("y", start = 0, direction = -1) +
scale_fill_manual(values = c("green", "red"), labels=c("complete","incomplete")) +
theme(legend.position = "bottom") +
theme(plot.title = element_text(hjust = 0.5)) +
ggtitle(paste("WHOIS in",numberOfMaliciousURLs,"malicious URLs\n(complete/incomplete for WHOIS)")) +
guides(fill=guide_legend(title=""))
grid.arrange(p1, p2, ncol = 2)
# Count the number of rows for each combination of https and who_is
train_websites_count <- train_websites %>%
filter(label == "good")
numberOfBenignURLs <- nrow(train_websites_count)
train_websites_count <- train_websites %>%
filter(label == "good") %>%
group_by(https, who_is) %>%
summarize(count = n())
# Create a pie chart with a legend
ggplot(train_websites_count, aes(x = "", y = count, fill = interaction(https, who_is))) +
geom_bar(width = 1, stat = "identity") +
coord_polar("y", start = 0, direction = 1) +
scale_fill_manual(values = c("blue", "green", "red", "orange")) +
theme(legend.position = "bottom") +
theme(plot.title = element_text(hjust = 0.5)) +
ggtitle(paste("(HTTPS.WHOIS) pair combination in",numberOfBenignURLs,"benign URLs\n(yes/no for HTTPS and complete/incomplete for WHOIS)")) +
guides(fill=guide_legend(title=""))
train_websites_top_10_bad <- train_websites_top_10 %>%
filter(label =="bad")
train_websites_top_10_good <- train_websites_top_10 %>%
filter(label =="good")
print(nrow(train_websites_top_10_bad))
print(nrow(train_websites_top_10_good))
write.csv(train_websites_top_10, "websites/train_websites_top_10.csv")
write.csv(test_websites_top_10, "websites/test_websites_top_10.csv")
write.csv(train_websites_top_10, "websites/train_websites_top_10.csv")
write.csv(test_websites_top_10, "websites/test_websites_top_10.csv")
separate_sampling <- list()
for (i in 1:K){
stan_data <- list(
N = N_list[[i]],
M = M_list[[i]],
js_len = js_len_list[[i]],
js_obf_len = js_obf_len_list[[i]],
https = https_list[[i]],
whois = whois_list[[i]],
js_len_pred = js_len_test_list[[i]],
js_obf_len_pred = js_obf_len_test_list[[i]],
https_pred = https_test_list[[i]],
whois_pred = whois_test_list[[i]],
label = label_list[[i]]
)
separate_sampling[[countries[i]]] <- model_separate$sample(data = stan_data, chains=4, iter_warmup = 2000, iter_sampling = 2000, show_messages=FALSE)#, refresh=0)
cat("\nSampling for country",countries[i],"\n")
}
library(rstan)
library(cmdstanr)
library(ggplot2)
library(dplyr)
library(tidyr)
library(grid)
library(gridExtra)
library(scales)
library(loo)
library(sentimentr)
library(stringr)
library(gridExtra)
library(MASS)
library(Metrics)
library(caret)
library(cvms)
library(tibble)
library(posterior)
library(purrr)
options(dplyr.summarise.inform = FALSE)
train_websites_top_5 <- read.csv("websites/train_websites_top_5.csv")
test_websites_top_5 <- read.csv("websites/test_websites_top_5.csv")
cat("Number of training data:",nrow(train_websites_top_5))
cat("\nNumber of testing data:",nrow(test_websites_top_5))
head(train_websites_top_5)
# Get unique country names
countries <- unique(train_websites_top_5$geo_loc)
# Get number of countries
K <- length(countries)
# Number of URLs per country, varying length of vector element
N_list = list()
# For each country, saving the number of URLs
for (country in countries) {
train_websites_country <- train_websites_top_5 %>%
filter(geo_loc == country)
N_list <- c(N_list, nrow(train_websites_country))
}
M_list = list()
# For each country, saving the number of URLs
for (country in countries) {
test_websites_country <- test_websites_top_5 %>%
filter(geo_loc == country)
M_list <- c(M_list, nrow(test_websites_country))
}
# The matrix of Javascript code, varying length of vector element
js_list = list()
for (country in countries) {
train_websites_country <- train_websites_top_5 %>%
filter(geo_loc == country)
js_list <- c(js_list, list(train_websites_country$js))
}
# The matrix of Javascript code, varying length of vector element
js_len_list = list()
for (country in countries) {
train_websites_country <- train_websites_top_5 %>%
filter(geo_loc == country)
js_len_list <- c(js_len_list, list(train_websites_country$js_len_bin))
}
# The matrix of Javascript code, varying length of vector element
js_obf_len_list = list()
for (country in countries) {
train_websites_country <- train_websites_top_5 %>%
filter(geo_loc == country)
js_obf_len_list <- c(js_obf_len_list, list(train_websites_country$js_obf_len_bin))
}
# The matrix of safety level of the URL, varying length of vector element
safety_list = list()
for (country in countries) {
train_websites_country <- train_websites_top_5 %>%
filter(geo_loc == country)
safety_list <- c(safety_list, list(train_websites_country$safety))
}
# The matrix of safety level of the URL, varying length of vector element
https_list = list()
for (country in countries) {
train_websites_country <- train_websites_top_5 %>%
filter(geo_loc == country)
https_list <- c(https_list, list(train_websites_country$https_bin))
}
# The matrix of safety level of the URL, varying length of vector element
whois_list = list()
for (country in countries) {
train_websites_country <- train_websites_top_5 %>%
filter(geo_loc == country)
whois_list <- c(whois_list, list(train_websites_country$whois_bin))
}
# Testing data
# The matrix of Javascript code, varying length of vector element
js_test_list = list()
for (country in countries) {
test_websites_country <- test_websites_top_5 %>%
filter(geo_loc == country)
js_test_list <- c(js_test_list, list(test_websites_country$js))
}
# The matrix of Javascript code, varying length of vector element
js_len_test_list = list()
for (country in countries) {
test_websites_country <- test_websites_top_5 %>%
filter(geo_loc == country)
js_len_test_list <- c(js_len_test_list, list(test_websites_country$js_len_bin))
}
# The matrix of Javascript code, varying length of vector element
js_obf_len_test_list = list()
for (country in countries) {
test_websites_country <- test_websites_top_5 %>%
filter(geo_loc == country)
js_obf_len_test_list <- c(js_obf_len_test_list, list(test_websites_country$js_obf_len_bin))
}
# The matrix of safety level of the URL, varying length of vector element
https_test_list = list()
for (country in countries) {
test_websites_country <- test_websites_top_5 %>%
filter(geo_loc == country)
https_test_list <- c(https_test_list, list(test_websites_country$https_bin))
}
# The matrix of safety level of the URL, varying length of vector element
whois_test_list = list()
for (country in countries) {
test_websites_country <- test_websites_top_5 %>%
filter(geo_loc == country)
whois_test_list <- c(whois_test_list, list(test_websites_country$whois_bin))
}
# The matrix of safety level of the URL, varying length of vector element
safety_test_list = list()
for (country in countries) {
test_websites_country <- test_websites_top_5 %>%
filter(geo_loc == country)
safety_test_list <- c(safety_test_list, list(test_websites_country$safety))
}
# The matrix of label of the URL (malicious/benign), varying length of vector element
label_list = list()
for (country in countries) {
train_websites_country <- train_websites_top_5 %>%
filter(geo_loc == country)
label_list <- append(label_list, list(train_websites_country$label_bin))
}
# The matrix of label of the URL (malicious/benign), varying length of vector element
label_test_list = list()
for (country in countries) {
test_websites_country <- test_websites_top_5 %>%
filter(geo_loc == country)
label_test_list <- append(label_test_list, list(test_websites_country$label_bin))
}
# Compiling the separate Stan model
file_separate <- file.path("model_separate.stan")
model_separate <- cmdstan_model(file_separate)
model_separate$compile(quiet = FALSE)
separate_sampling <- list()
for (i in 1:K){
stan_data <- list(
N = N_list[[i]],
M = M_list[[i]],
js_len = js_len_list[[i]],
js_obf_len = js_obf_len_list[[i]],
https = https_list[[i]],
whois = whois_list[[i]],
js_len_pred = js_len_test_list[[i]],
js_obf_len_pred = js_obf_len_test_list[[i]],
https_pred = https_test_list[[i]],
whois_pred = whois_test_list[[i]],
label = label_list[[i]]
)
separate_sampling[[countries[i]]] <- model_separate$sample(data = stan_data, chains=4, iter_warmup = 2000, iter_sampling = 2000, show_messages=FALSE)#, refresh=0)
cat("\nSampling for country",countries[i],"\n")
}
# Compiling the pooled Stan model
file_pooled <- file.path("model_pooled.stan")
model_pooled <- cmdstan_model(file_pooled)
model_pooled$compile(quiet = FALSE)
stan_data_pooled <- list(
Nmax = Nmax,
Mmax = Mmax,
K = K,
N_list = N_list,
M_list = M_list,
js_len_list = as.matrix(do.call(rbind, js_len_list)),
js_obf_len_list = as.matrix(do.call(rbind, js_obf_len_list)),
https_list = as.matrix(do.call(rbind, https_list)),
whois_list = as.matrix(do.call(rbind, whois_list)),
js_len_pred_list = as.matrix(do.call(rbind, js_len_test_list)),
js_obf_len_pred_list = as.matrix(do.call(rbind, js_obf_len_test_list)),
https_pred_list = as.matrix(do.call(rbind, https_test_list)),
whois_pred_list = as.matrix(do.call(rbind, whois_test_list)),
label_list = as.matrix(do.call(rbind, label_list))
)
# Get unique country names
countries <- unique(train_websites_top_5$geo_loc)
# Get number of countries
K <- length(countries)
# Number of URLs per country, varying length of vector element
N_list = list()
# For each country, saving the number of URLs
for (country in countries) {
train_websites_country <- train_websites_top_5 %>%
filter(geo_loc == country)
N_list <- c(N_list, nrow(train_websites_country))
}
# Maximum length of training URLs for all countries
Nmax <- N_list[[which.max(N_list)]]
M_list = list()
# For each country, saving the number of URLs
for (country in countries) {
test_websites_country <- test_websites_top_5 %>%
filter(geo_loc == country)
M_list <- c(M_list, nrow(test_websites_country))
}
# Maximum length of training URLs for all countries
Mmax <- M_list[[which.max(M_list)]]
# The matrix of Javascript code
js_len_list = list()
for (country in countries) {
train_websites_country <- train_websites_top_5 %>%
filter(geo_loc == country)
js_len_list <- c(js_len_list, list(train_websites_country$js_len_bin))
}
js_len_list <- map(js_len_list, function(x) {return(c(x, rep(0, Nmax - length(x))))})
# The matrix of Javascript obfuscated code
js_obf_len_list = list()
for (country in countries) {
train_websites_country <- train_websites_top_5 %>%
filter(geo_loc == country)
js_obf_len_list <- c(js_obf_len_list, list(train_websites_country$js_obf_len_bin))
}
js_obf_len_list <- map(js_obf_len_list, function(x) {return(c(x, rep(0, Nmax - length(x))))})
# The matrix of safety level of the URL, varying length of vector element
https_list = list()
for (country in countries) {
train_websites_country <- train_websites_top_5 %>%
filter(geo_loc == country)
https_list <- c(https_list, list(train_websites_country$https_bin))
}
https_list <- map(https_list, function(x) {return(c(x, rep(0, Nmax - length(x))))})
# The matrix of safety level of the URL, varying length of vector element
whois_list = list()
for (country in countries) {
train_websites_country <- train_websites_top_5 %>%
filter(geo_loc == country)
whois_list <- c(whois_list, list(train_websites_country$whois_bin))
}
whois_list <- map(whois_list, function(x) {return(c(x, rep(0, Nmax - length(x))))})
# The matrix of Javascript code, varying length of vector element
js_len_test_list = list()
for (country in countries) {
test_websites_country <- test_websites_top_5 %>%
filter(geo_loc == country)
js_len_test_list <- c(js_len_test_list, list(test_websites_country$js_len_bin))
}
js_len_test_list <- map(js_len_test_list, function(x) {return(c(x, rep(0, Mmax - length(x))))})
# The matrix of Javascript code, varying length of vector element
js_obf_len_test_list = list()
for (country in countries) {
test_websites_country <- test_websites_top_5 %>%
filter(geo_loc == country)
js_obf_len_test_list <- c(js_obf_len_test_list, list(test_websites_country$js_obf_len_bin))
}
js_obf_len_test_list <- map(js_obf_len_test_list, function(x) {return(c(x, rep(0, Mmax - length(x))))})
# The matrix of safety level of the URL, varying length of vector element
https_test_list = list()
for (country in countries) {
test_websites_country <- test_websites_top_5 %>%
filter(geo_loc == country)
https_test_list <- c(https_test_list, list(test_websites_country$https_bin))
}
https_test_list <- map(https_test_list, function(x) {return(c(x, rep(0, Mmax - length(x))))})
# The matrix of safety level of the URL, varying length of vector element
whois_test_list = list()
for (country in countries) {
test_websites_country <- test_websites_top_5 %>%
filter(geo_loc == country)
whois_test_list <- c(whois_test_list, list(test_websites_country$whois_bin))
}
whois_test_list <- map(whois_test_list, function(x) {return(c(x, rep(0, Mmax - length(x))))})
# The matrix of label of the URL (malicious/benign), varying length of vector element
label_list = list()
for (country in countries) {
train_websites_country <- train_websites_top_5 %>%
filter(geo_loc == country)
label_list <- append(label_list, list(train_websites_country$label_bin))
}
label_list <- map(label_list, function(x) {return(c(x, rep(0, Nmax - length(x))))})
# The matrix of label of the URL (malicious/benign), varying length of vector element
label_test_list = list()
for (country in countries) {
test_websites_country <- test_websites_top_5 %>%
filter(geo_loc == country)
label_test_list <- append(label_test_list, list(test_websites_country$label_bin))
}
label_test_list <- map(label_test_list, function(x) {return(c(x, rep(0, Mmax - length(x))))})
stan_data_pooled <- list(
Nmax = Nmax,
Mmax = Mmax,
K = K,
N_list = N_list,
M_list = M_list,
js_len_list = as.matrix(do.call(rbind, js_len_list)),
js_obf_len_list = as.matrix(do.call(rbind, js_obf_len_list)),
https_list = as.matrix(do.call(rbind, https_list)),
whois_list = as.matrix(do.call(rbind, whois_list)),
js_len_pred_list = as.matrix(do.call(rbind, js_len_test_list)),
js_obf_len_pred_list = as.matrix(do.call(rbind, js_obf_len_test_list)),
https_pred_list = as.matrix(do.call(rbind, https_test_list)),
whois_pred_list = as.matrix(do.call(rbind, whois_test_list)),
label_list = as.matrix(do.call(rbind, label_list))
)
pooled_sampling <- model_pooled$sample(data = stan_data_pooled, chains=4, iter_warmup = 2000, iter_sampling = 2000)
